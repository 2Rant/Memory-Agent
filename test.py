# from copy import deepcopy
# import uuid
# from qdrant_client import QdrantClient
# from qdrant_client.models import Distance, VectorParams
# from qdrant_client.models import PointStruct, PointIdsList
# from utils import (
#     get_embedding, parse_messages, FACT_RETRIEVAL_PROMPT, 
#     remove_code_blocks, extract_json, get_update_memory_messages, 
#     LME_JUDGE_MODEL_TEMPLATE, LME_ANSWER_PROMPT 
# )
# from lme_eval import lme_grader 
# from dotenv import load_dotenv
# import os
# import json
# from openai import OpenAI
# import pytz
# from datetime import datetime, timezone
# from tqdm import tqdm
# from concurrent.futures import ThreadPoolExecutor, as_completed

# load_dotenv()

# OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
# BASE_URL = os.getenv("OPENAI_BASE_URL")
# MODEL_NAME = os.getenv("MODEL_NAME", "gpt-4o-mini")
# openai_client = OpenAI(api_key=OPENAI_API_KEY, base_url=BASE_URL)
# dimension=1536
# collection_name = "lme"
# # vect_store_client = QdrantClient(path="./qdrant_db")
# vect_store_client = QdrantClient(url="https://bb9a565c-40a3-471b-917b-4fbaeb99446f.us-east4-0.gcp.cloud.qdrant.io:6333",
#                                   api_key="eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3MiOiJtIn0.07poGFmT_he2JW-a_Qy4CThgHpCG-uSC4le2VOlPTUo")
# topk = 5
# system_prompt = FACT_RETRIEVAL_PROMPT


# def search(collection_name, vect_store_client, query_vector, top_k=5):
#     search_result = vect_store_client.query_points(
#         collection_name=collection_name,
#         query=query_vector,
#         with_payload=True,
#         limit=top_k
#     ).points
#     # print(search_result)
#     return search_result

# def insert(collection_name, vect_store_client, vectors, payloads=None):
#     points = [
#         PointStruct(id=idx, vector=vector, payload=payloads[idx])
#         for idx, vector in enumerate(vectors)
#     ]
#     vect_store_client.upsert(
#         collection_name=collection_name,
#         points=points
#     )

# def generate_response(llm_client, question, question_date, context):
#     prompt = LME_ANSWER_PROMPT.format(
#         question=question,
#         question_date=question_date,
#         context=context
#     )
#     response = llm_client.chat.completions.create(
#                 model=MODEL_NAME,
#                 messages=[{"role": "system", "content": prompt}],
#                 # response_format={"type": "json_object"},
#                 temperature=0,
#             )

#     return response
 
# def process_user_memory_infer(line):
#     dates = line.get("haystack_dates")
#     sessions = line.get("haystack_sessions")
#     question_date = line.get("question_date")
#     question_date = question_date + " UTC"
#     question_date_format = "%Y/%m/%d (%a) %H:%M UTC"
#     question_date_string = datetime.strptime(question_date, question_date_format).replace(tzinfo=timezone.utc)
#     question = line.get("question")
#     golden_answer = line.get("answer") 

#     operation_counts = {"ADD": 0, "UPDATE": 0, "DELETE": 0, "NONE": 0}

#     for session_id, session in enumerate(sessions):
#         date = dates[session_id] + " UTC"
#         date_format = "%Y/%m/%d (%a) %H:%M UTC"
#         date_string = datetime.strptime(date, date_format).replace(tzinfo=timezone.utc)
        
#         parsed_messages = parse_messages(session) 
#         # print("parsed_messages:", parsed_messages) 
#         user_prompt = f"Input:\n{parsed_messages}"
#         llm_response = openai_client.chat.completions.create(
#             model=MODEL_NAME,
#             messages=[
#                 {"role": "system", "content": system_prompt},
#                 {"role": "user", "content": user_prompt}
#             ],
#             response_format={"type": "json_object"},
#         )
#         response = llm_response.choices[0].message.content
#         # print(f"LLM è¿”å›çš„åŸå§‹å“åº”: {response}")
#         if response == '{"facts" : []}':
#             # print("parsed_messages:", parsed_messages)
#             pass
#         try:
#             response = remove_code_blocks(response)
#             if not response.strip():
#                 new_retrieved_facts = []
#             else:
#                 try:
#                     new_retrieved_facts = json.loads(response)["facts"]
#                 except json.JSONDecodeError:
#                     extracted_json = extract_json(response)
#                     new_retrieved_facts = json.loads(extracted_json)["facts"]
#         except Exception as e:
#             print(f"Error in new_retrieved_facts: {e}")
#             new_retrieved_facts = []
#         # print(f"æ–°æ£€ç´¢åˆ°çš„äº‹å®: {new_retrieved_facts}") 

#         if not new_retrieved_facts:
#             # print("No new facts retrieved; skipping memory update.")
#             continue
            
#         retrieved_old_facts = []
#         new_message_embeddings = {} 
#         try:
#             for fact in new_retrieved_facts:
#                 embedding_vector = get_embedding(openai_client, fact, dimension=dimension)
#                 new_message_embeddings[fact] = embedding_vector 
                
#                 existing_memories = search(collection_name, vect_store_client, embedding_vector, top_k=5)
#                 for mem in existing_memories:
#                     retrieved_old_facts.append({"id": mem.id, "text": mem.payload.get("data", "")})
#                     # print("mem:", mem) 
#         except Exception as e:
#             print(f"ç”ŸæˆåµŒå…¥æ—¶å‡ºé”™ï¼Œè¯·æ£€æŸ¥æ‚¨çš„ API Key å’Œç½‘ç»œè¿æ¥ï¼š{e}")

#         unique_data = {}
#         for item in retrieved_old_facts:
#             unique_data[item["id"]] = item
#         retrieved_old_facts = list(unique_data.values())

#         temp_uuid_mapping = {}
#         for idx, item in enumerate(retrieved_old_facts):
#             temp_uuid_mapping[str(idx)] = item["id"]
#             retrieved_old_facts[idx]["id"] = str(idx)
#         # print(f"ä¸´æ—¶ UUID æ˜ å°„: {temp_uuid_mapping}") 
#         # print(f"ç”¨äºè®°å¿†æ›´æ–°çš„æ—§äº‹å®: {retrieved_old_facts}") 

#         if new_retrieved_facts:
#             memory_action_prompt = get_update_memory_messages(retrieved_old_facts, new_retrieved_facts)
#             response = openai_client.chat.completions.create(
#                 model=MODEL_NAME,
#                 messages=[{"role": "user", "content": memory_action_prompt}],
#                 response_format={"type": "json_object"},
#             )
#             update_response = response.choices[0].message.content
#             # print("update_response:", update_response)
#             try:
#                 if not update_response.strip() or not update_response:
#                     # print("Empty response for memory update.")
#                     new_memories_with_actions = {}
#                 else:
#                     response = remove_code_blocks(update_response)
#                     new_memories_with_actions = json.loads(response)
#             except Exception as e:
#                 print(f"Invalid JSON response: {e}")
#                 new_memories_with_actions = {}

#         else:
#             new_memories_with_actions = {}

#         returned_memories = []
#         # print(f"new_memories_with_actions: {new_memories_with_actions}")
#         try:
#             for resp in new_memories_with_actions.get("memory", []):
#                 try:
#                     action_text = resp.get("text")
#                     if not action_text:
#                         print("Skipping memory entry because of empty `text` field.")
#                         continue
                        
#                     event_type = resp.get("event")
#                     if event_type in operation_counts:
#                         operation_counts[event_type] += 1
                        
#                     embedding_vector = get_embedding(openai_client, action_text, dimension=dimension)
                    
#                     if event_type == "ADD":
#                         memory_id = str(uuid.uuid4())
#                         vect_store_client.upsert(
#                         collection_name=collection_name, wait=True,
#                         points=[ PointStruct(
#                                     id=memory_id, vector=embedding_vector, 
#                                     payload={ "data": action_text, "created_at": date_string.isoformat()}
#                                 ) ],
#                         )
#                         returned_memories.append({"id": memory_id, "memory": action_text, "event": event_type}) 
                    
#                     elif event_type == "UPDATE":
#                         points_data = vect_store_client.retrieve(
#                             collection_name=collection_name,
#                             ids=[temp_uuid_mapping.get(resp.get("id"))],
#                             with_payload=True, 
#                         )
#                         result = points_data[0] if points_data else None
#                         if result:
#                             old_memory = result.payload.get("data", "")
#                         else:
#                             old_memory = ""

#                         new_updated_at = date_string.isoformat()
#                         result.payload["data"] = action_text
#                         result.payload["updated_at"] = new_updated_at
#                         vect_store_client.upsert(
#                             collection_name=collection_name,
#                             points=[ PointStruct(
#                                         id=temp_uuid_mapping.get(resp.get("id")), 
#                                         vector=embedding_vector, 
#                                         payload=result.payload
#                                     ) ],
#                         )
#                         returned_memories.append( 
#                             {
#                                 "id": temp_uuid_mapping.get(resp.get("id"), "update_get_id_error"),
#                                 "memory": action_text,
#                                 "event": event_type,
#                                 "previous_memory": old_memory,
#                             }
#                         )
#                     elif event_type == "DELETE":
#                         if temp_uuid_mapping.get(resp.get("id")) is None:
#                             print(f"Warning: Attempted DELETE on unknown temporary ID: {resp.get('id')}. Skipping.")
#                             continue
#                         # print(f"Deleting memory with ID: {temp_uuid_mapping.get(resp.get('id'))}")
#                         vect_store_client.delete(
#                             collection_name=collection_name,
#                             points_selector=PointIdsList(
#                                 points=[temp_uuid_mapping.get(resp.get("id"))]
#                             ),
#                         )
#                         returned_memories.append(
#                             {
#                                 "id": temp_uuid_mapping.get(resp.get("id"), "delete_get_id_error"),
#                                 "memory": action_text,
#                                 "event": event_type,
#                             }
#                         )
#                     elif event_type == "NONE":
#                         returned_memories.append(
#                             {
#                                 "id": temp_uuid_mapping.get(resp.get("id"), "none_get_id_error"),
#                                 "memory": action_text,
#                                 "event": event_type,
#                             }
#                         )
#                 except Exception as e:
#                     print(f"Error processing memory action {resp}: {e}")       
#         except Exception as e:
#             print(f"Error iterating new_memories_with_actions: {e}")

#         print(f"æœ€ç»ˆè¿”å›çš„è®°å¿†æ“ä½œç»“æœ: {returned_memories}") 

#     return operation_counts


# def process_user_memory(line):
#     dates = line.get("haystack_dates")
#     sessions = line.get("haystack_sessions")
#     returned_memories = []
#     operation_counts = {"ADD": 0, "UPDATE": 0, "DELETE": 0, "NONE": 0}
#     for session_id, session in enumerate(sessions):
#         date = dates[session_id] + " UTC"
#         date_format = "%Y/%m/%d (%a) %H:%M UTC"
#         date_string = datetime.strptime(date, date_format).replace(tzinfo=timezone.utc)

#         # for message in session:
#         #     message_dict = message
#         #     if isinstance(message, str):
#         #         try:
#         #             message_dict = json.loads(message)
#         #         except json.JSONDecodeError:
#         #             print(f"æ— æ³•è§£ææ¶ˆæ¯ä¸º JSON: {message}")
#         #             continue

#         #     metadata = {
#         #         "created_at": date_string.isoformat(),
#         #     }

#         #     memory_id = str(uuid.uuid4())
#         #     if message_dict["role"] == "system":
#         #         continue
            
#         #     metadata["role"] = message_dict["role"]
#         #     metadata["data"] = message_dict["content"]

#         #     msg_content = message_dict["content"]
#         #     embedding_vector = get_embedding(openai_client, msg_content, dimension=dimension)
#         #     vect_store_client.upsert(
#         #                 collection_name=collection_name, wait=True,
#         #                 points=[ PointStruct(
#         #                             id=memory_id, vector=embedding_vector, 
#         #                             payload=metadata
#         #                         ) ],
#         #                 )
#         #     operation_counts["ADD"] += 1
#         #     returned_memories.append(
#         #         {
#         #             "id": memory_id,
#         #             "memory": msg_content,
#         #             "event": "ADD",
#         #             # "actor_id": actor_name if actor_name else None,
#         #             "role": message_dict["role"],
#         #         }
#         #     )

#         parsed_messages = parse_messages(session)
#         user_prompt = f"Input:\n{parsed_messages}"
#         llm_response = openai_client.chat.completions.create(
#             model=MODEL_NAME,
#             messages=[
#                 {"role": "system", "content": system_prompt},
#                 {"role": "user", "content": user_prompt}
#             ],
#             response_format={"type": "json_object"},
#         )
#         response = llm_response.choices[0].message.content
#         # print(f"LLM è¿”å›çš„åŸå§‹å“åº”: {response}")
#         if response == '{"facts" : []}':
#             # print("parsed_messages:", parsed_messages)
#             continue
#         try:
#             response = remove_code_blocks(response)
#             if not response.strip():
#                 new_retrieved_facts = []
#             else:
#                 try:
#                     new_retrieved_facts = json.loads(response)["facts"]
#                 except json.JSONDecodeError:
#                     extracted_json = extract_json(response)
#                     new_retrieved_facts = json.loads(extracted_json)["facts"]
#         except Exception as e:
#             print(f"Error in new_retrieved_facts: {e}")
#             new_retrieved_facts = []
#         # print(f"æ–°æ£€ç´¢åˆ°çš„äº‹å®: {new_retrieved_facts}")
#         for fact in new_retrieved_facts:
#             embedding_vector = get_embedding(openai_client, fact, dimension=dimension)
#             memory_id = str(uuid.uuid4())
#             vect_store_client.upsert(
#                 collection_name=collection_name, wait=True,
#                 points=[ PointStruct(
#                             id=memory_id, vector=embedding_vector, 
#                             payload={ "data": fact, "created_at": date_string.isoformat()}
#                         ) ],
#                 )
#             operation_counts["ADD"] += 1
#             returned_memories.append(
#                 {
#                     "id": memory_id,
#                     "memory": fact,
#                     "event": "ADD",
#                 }
#             )
#         print(f"æœ€ç»ˆè¿”å›çš„è®°å¿†æ“ä½œç»“æœ: {returned_memories}")
        
#     return operation_counts


# def response_user(line):
#     question = line.get("question")
#     question_date = line.get("question_date")
#     question_date = question_date + " UTC"
#     question_date_format = "%Y/%m/%d (%a) %H:%M UTC"
#     question_date_string = datetime.strptime(question_date, question_date_format).replace(tzinfo=timezone.utc)
#     question = line.get("question")
#     question_vector = get_embedding(openai_client, question, dimension=dimension)
#     retrieved_memories = search(collection_name, vect_store_client, question_vector, top_k=topk)
#     # context = "\n".join([mem.payload.get("data", "") for mem in retrieved_memories])
#     memories_str = (
#             "\n".join(
#                 f"- {mem.payload.get('created_at', '')}: {mem.payload.get('data', '')}"
#                 for mem in retrieved_memories
#             )
#         )
#     response = generate_response(openai_client, question, question_date_string, memories_str)
#     answer = response.choices[0].message.content

#     return answer

# def process_and_evaluate_user(line, user_index, client, infer):
#     """
#     å°è£…å•ä¸ªç”¨æˆ·çš„æ‰€æœ‰å¤„ç†æ­¥éª¤ï¼Œä»¥ä¾¿å¹¶è¡Œæ‰§è¡Œã€‚
#     è¿”å›ä¸€ä¸ªåŒ…å«æ‰€æœ‰ç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸ã€‚
#     """
#     try:
#         if infer:
#             memory_counts = process_user_memory_infer(line)
#         else:
#             memory_counts = process_user_memory(line)
        
#         answer = response_user(line)
#         golden_answer = line.get("answer") 
#         question = line.get("question")
        
#         is_correct = lme_grader(client, question, golden_answer, answer)
        
#         return {
#             "index": user_index,
#             "is_correct": is_correct,
#             "counts": memory_counts,
#             "question": question,
#             "answer": answer,
#             "golden_answer": golden_answer
#         }
#     except Exception as e:
#         print(f"Error processing user {user_index} ({line.get('question', 'Unknown')[:20]}...): {e}")
#         return {
#             "index": user_index,
#             "is_correct": False,
#             "counts": {"ADD": 0, "UPDATE": 0, "DELETE": 0, "NONE": 0},
#             "question": line.get("question", "N/A")
#         }


# if __name__ == "__main__":
#     # æ¸…ç©ºå¹¶é‡æ–°åˆ›å»º Qdrant é›†åˆ
#     try:
#         if vect_store_client.collection_exists(collection_name=collection_name):
#             vect_store_client.delete_collection(collection_name=collection_name)
#         vect_store_client.create_collection(
#             collection_name=collection_name,
#             vectors_config=VectorParams(size=dimension, distance=Distance.DOT),
#         )
#     except Exception as e:
#         print(f"æ¸…ç©º Qdrant é›†åˆå¤±è´¥: {e}. è¯·æ£€æŸ¥ Qdrant å®¢æˆ·ç«¯è¿æ¥ã€‚")
#         exit()

#     with open("./data/longmemeval_s_cleaned.json", "r") as f:
#         lines = json.load(f)[:50]
    
#     print(f"å·²åŠ è½½ {len(lines)} ä¸ªç”¨æˆ·/é—®é¢˜ã€‚")

#     user_detail_results = [] 
#     total_memory_counts = {"ADD": 0, "UPDATE": 0, "DELETE": 0, "NONE": 0}
    
#     MAX_WORKERS = 10
#     infer = False

#     futures = []

#     print(f"å¼€å§‹ä½¿ç”¨ {MAX_WORKERS} ä¸ªçº¿ç¨‹å¹¶è¡Œå¤„ç†...")
    
#     with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
#         for idx, line in enumerate(lines):
#             future = executor.submit(process_and_evaluate_user, line, idx + 1, openai_client, infer=infer)
#             futures.append(future)
        
#         for future in tqdm(as_completed(futures), total=len(futures), desc="è¯„ä¼°è¿›åº¦"):
#             result = future.result()
#             user_detail_results.append(result)

#     user_detail_results.sort(key=lambda x: x.get("index", 0))

#     correct_count = 0
#     total_evaluated = len(user_detail_results)

#     for res in user_detail_results:
#         if res.get("is_correct"):
#             correct_count += 1
        
#         counts = res.get("counts", {})
#         for key in total_memory_counts:
#             total_memory_counts[key] += counts.get(key, 0)

#     print("\n\n==================================================")
#     print("             ğŸ¯ æœ€ç»ˆè¯„ä¼°ç»“æœ") 
#     print("==================================================")

#     if total_evaluated > 0:
#         final_accuracy = correct_count / total_evaluated
#         print(f"æ€»è¯„ä¼°é—®é¢˜æ•°: {total_evaluated}")
#         print(f"æ­£ç¡®å›ç­”æ•°: {correct_count}")
#         print(f"æœ€ç»ˆæ€»å‡†ç¡®ç‡: {final_accuracy:.4f} ({final_accuracy * 100:.2f}%)")
#     else:
#         print("æ²¡æœ‰è¯„ä¼°ä»»ä½•é—®é¢˜ã€‚")
#     print("==================================================")

#     print("\n\n==================================================")
#     print("        ğŸ“Š è¯¦ç»†è®°å¿†æ“ä½œç»Ÿè®¡ (æŒ‰ç”¨æˆ·)")
#     print("==================================================")

#     for res in user_detail_results:
#         user_index = res["index"]
#         is_correct = res["is_correct"]
#         counts = res["counts"]
#         question = res["question"]
#         answer = res.get("answer", "N/A")
#         golden_answer = res.get("golden_answer", "N/A")
#         status = "âœ… CORRECT" if is_correct else "âŒ WRONG"
        
#         print(f"\n--- ç”¨æˆ·/é—®é¢˜ {user_index} ---")
#         print(f"  é—®é¢˜: {question[:60]}...")
#         print(f"  æ¨¡å‹å›ç­”: {answer[:60]}...")
#         print(f"  æ ‡å‡†ç­”æ¡ˆ: {golden_answer[:60]}...")
#         print(f"  è¯„ä¼°ç»“æœ: {status}")
#         print(f"  è®°å¿†æ“ä½œ: ADD={counts.get('ADD', 0)}, UPDATE={counts.get('UPDATE', 0)}, DELETE={counts.get('DELETE', 0)}, NONE={counts.get('NONE', 0)}")

#     print("\n--- æ‰€æœ‰ç”¨æˆ·çš„è®°å¿†æ“ä½œæ€»è§ˆ ---")
#     print(f"  ADD (æ–°å¢):    {total_memory_counts['ADD']}")
#     print(f"  UPDATE (æ›´æ–°): {total_memory_counts['UPDATE']}")
#     print(f"  DELETE (åˆ é™¤): {total_memory_counts['DELETE']}")
#     print(f"  NONE (æ— æ“ä½œ): {total_memory_counts['NONE']}")
#     print("==================================================")


import os
import shutil
import random
from datetime import datetime, timezone
from qdrant_client import QdrantClient
from qdrant_client.models import PointStruct, VectorParams, Distance
import uuid
# --- 1. é…ç½® ---
DB_PATH = "./qdrant_db" # ä¸´æ—¶çš„æ•°æ®åº“è·¯å¾„
COLLECTION_NAME = "test_update_collection"
DIMENSION = 4  # ä½¿ç”¨ä¸€ä¸ªå°çš„ç»´åº¦æ¥å¿«é€Ÿæµ‹è¯•
ITEM_ID = str(uuid.uuid4()) # æˆ‘ä»¬å°†è¦æ›´æ–°çš„å›ºå®š ID

# --- 2. åˆå§‹åŒ– Qdrant å®¢æˆ·ç«¯å’Œé›†åˆ ---
# ç¡®ä¿æˆ‘ä»¬ä»ä¸€ä¸ªå¹²å‡€çš„çŠ¶æ€å¼€å§‹
# if os.path.exists(DB_PATH):
#     print(f"å‘ç°æ—§çš„æµ‹è¯•æ•°æ®åº“ï¼Œæ­£åœ¨åˆ é™¤: {DB_PATH}")
#     shutil.rmtree(DB_PATH)

# ä½¿ç”¨ Qdrant æ–‡ä»¶å­˜å‚¨
client = QdrantClient(path=DB_PATH)

print(f"\nåˆ›å»º Qdrant é›†åˆ: {COLLECTION_NAME}")
# ä½¿ç”¨ recreate_collection æ¥ç¡®ä¿æ¯æ¬¡è¿è¡Œéƒ½æ˜¯å…¨æ–°çš„
client.recreate_collection(
    collection_name=COLLECTION_NAME,
    # ç»´åº¦å’Œè·ç¦»å•ä½åº”ä¸æ‚¨çš„ä¸»è„šæœ¬åŒ¹é…
    vectors_config=VectorParams(size=DIMENSION, distance=Distance.DOT) 
)
print("é›†åˆåˆ›å»ºæˆåŠŸã€‚")

try:
    # --- æ­¥éª¤ 1: æ’å…¥ (ADD) - ç‰ˆæœ¬ 1 ---
    print("\n--- æ­¥éª¤ 1: æ’å…¥ 'ç‰ˆæœ¬ 1' æ•°æ® ---")
    v1_text = "è¿™æ˜¯åŸå§‹ç‰ˆæœ¬çš„æ•°æ®"
    v1_vector = [random.random() for _ in range(DIMENSION)]
    v1_created_at = datetime.now(timezone.utc).isoformat()
    
    v1_payload = {
        "data": v1_text,
        "created_at": v1_created_at
        # æ³¨æ„ï¼šv1 æ²¡æœ‰ updated_at å­—æ®µ
    }
    
    v1_point = PointStruct(id=ITEM_ID, vector=v1_vector, payload=v1_payload)
    
    client.upsert(
        collection_name=COLLECTION_NAME,
        points=[v1_point],
        wait=True # ç­‰å¾…æ“ä½œå®Œæˆ
    )
    print(f"  > å·²æ’å…¥ ID: {ITEM_ID}")
    print(f"  > Payload: {v1_payload}")

    # --- æ­¥éª¤ 2: éªŒè¯ (VERIFY) - ç‰ˆæœ¬ 1 ---
    print("\n--- æ­¥éª¤ 2: éªŒè¯ 'ç‰ˆæœ¬ 1' æ•°æ® ---")
    retrieved_v1_list = client.retrieve(
        collection_name=COLLECTION_NAME,
        ids=[ITEM_ID],
        with_payload=True
    )
    
    assert len(retrieved_v1_list) == 1, "é”™è¯¯ï¼šæ’å…¥åæœªèƒ½æ£€ç´¢åˆ°æ•°æ®ï¼"
    retrieved_v1_point = retrieved_v1_list[0]
    
    print(f"  > æ£€ç´¢ç»“æœ: {retrieved_v1_point}")
    assert retrieved_v1_point.payload["data"] == v1_text, "é”™è¯¯ï¼šv1 çš„ data å­—æ®µä¸åŒ¹é…ï¼"
    assert retrieved_v1_point.payload["created_at"] == v1_created_at, "é”™è¯¯ï¼šv1 çš„ created_at å­—æ®µä¸åŒ¹é…ï¼"
    
    print("  > éªŒè¯æˆåŠŸï¼š 'ç‰ˆæœ¬ 1' æ•°æ®å·²æ­£ç¡®å­˜å‚¨ã€‚")

    # --- æ­¥éª¤ 3: æ›´æ–° (UPDATE) - ç‰ˆæœ¬ 2 ---
    print("\n--- æ­¥éª¤ 3: æ›´æ–° (Upsert) 'ç‰ˆæœ¬ 2' æ•°æ® (æ¨¡æ‹Ÿæ‚¨çš„è„šæœ¬) ---")
    
    # 1. è·å–æ—§çš„ payload
    original_payload = retrieved_v1_point.payload
    
    # 2. å‡†å¤‡æ–°æ•°æ®
    v2_text = "è¿™æ˜¯å·²æ›´æ–°çš„ç‰ˆæœ¬"
    v2_vector = [random.random() for _ in range(DIMENSION)] # æ¨¡æ‹Ÿæ–°çš„åµŒå…¥å‘é‡
    v2_updated_at = datetime.now(timezone.utc).isoformat()

    # 3. åˆ›å»ºæ–°çš„ payloadï¼Œä¿®æ”¹ data å’Œ updated_atï¼Œä½†ä¿ç•™ created_at
    v2_payload = original_payload.copy() # å¤åˆ¶æ—§ payload
    v2_payload["data"] = v2_text         # æ›´æ–° data
    v2_payload["updated_at"] = v2_updated_at # æ·»åŠ  updated_at
    
    # 4. ç”¨æ–°å‘é‡å’Œæ–° payload è¦†ç›–æ—§çš„ ID
    v2_point = PointStruct(id=ITEM_ID, vector=v2_vector, payload=v2_payload)
    
    client.upsert(
        collection_name=COLLECTION_NAME,
        points=[v2_point],
        wait=True
    )
    print(f"  > å·²æ›´æ–° ID: {ITEM_ID}")
    print(f"  > æ–° Payload: {v2_payload}")

    # --- æ­¥éª¤ 4: éªŒè¯ (VERIFY) - ç‰ˆæœ¬ 2 ---
    print("\n--- æ­¥éª¤ 4: éªŒè¯ 'ç‰ˆæœ¬ 2' æ•°æ® ---")
    retrieved_v2_list = client.retrieve(
        collection_name=COLLECTION_NAME,
        ids=[ITEM_ID],
        with_payload=True
    )
    
    assert len(retrieved_v2_list) == 1, "é”™è¯¯ï¼šæ›´æ–°åæœªèƒ½æ£€ç´¢åˆ°æ•°æ®ï¼"
    retrieved_v2_point = retrieved_v2_list[0]

    print(f"  > æ£€ç´¢ç»“æœ: {retrieved_v2_point}")
    
    # éªŒè¯æ•°æ®æ˜¯å¦å·²æ›´æ–°
    assert retrieved_v2_point.payload["data"] == v2_text, "é”™è¯¯ï¼šv2 çš„ data å­—æ®µæœªæ›´æ–°ï¼"
    # éªŒè¯ created_at æ˜¯å¦è¢«ä¿ç•™
    assert retrieved_v2_point.payload["created_at"] == v1_created_at, "é”™è¯¯ï¼šcreated_at å­—æ®µåœ¨æ›´æ–°æ—¶ä¸¢å¤±äº†ï¼"
    # éªŒè¯ updated_at æ˜¯å¦å·²æ·»åŠ 
    assert retrieved_v2_point.payload["updated_at"] == v2_updated_at, "é”™è¯¯ï¼šupdated_at å­—æ®µæœªæ­£ç¡®æ·»åŠ ï¼"
    
    print("\n==============================================")
    print("âœ… éªŒè¯æˆåŠŸï¼Qdrant çš„ 'è¯»å–-ä¿®æ”¹-å†™å›' æ›´æ–°é€»è¾‘å·¥ä½œæ­£å¸¸ã€‚")
    print("==============================================")

finally:
    # --- æ­¥éª¤ 5: æ¸…ç† ---
    print(f"\n--- æ­¥éª¤ 5: æ¸…ç† ---")
    # client.close()
    # if os.path.exists(DB_PATH):
    #     shutil.rmtree(DB_PATH)
    #     print(f"å·²åˆ é™¤ä¸´æ—¶ Qdrant æ•°æ®åº“: {DB_PATH}")