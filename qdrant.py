
from copy import deepcopy
import uuid
from qdrant_client import QdrantClient
from qdrant_client.models import Distance, VectorParams
from qdrant_client.models import PointStruct
from utils import get_embedding, parse_messages, FACT_RETRIEVAL_PROMPT, remove_code_blocks, extract_json, get_update_memory_messages, LME_JUDGE_MODEL_TEMPLATE, LME_ANSWER_PROMPT 
from lme_eval import lme_grader
from dotenv import load_dotenv
import os
import json
from openai import OpenAI
import pytz
from datetime import datetime, timezone

load_dotenv()

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
BASE_URL = os.getenv("OPENAI_BASE_URL")
MODEL_NAME = os.getenv("MODEL_NAME", "gpt-4o-mini")
openai_client = OpenAI(api_key=OPENAI_API_KEY, base_url=BASE_URL)
dimension=1536
collection_name = "lme_test"
vect_store_client = QdrantClient(path="./qdrant_db")
topk = 5
system_prompt = FACT_RETRIEVAL_PROMPT

if not os.path.exists("./qdrant_db/collection/" + collection_name):
    vect_store_client.create_collection(
        collection_name=collection_name,
        vectors_config=VectorParams(size=dimension, distance=Distance.DOT),
    )

def search(collection_name, vect_store_client, query_vector, top_k=5):
    search_result = vect_store_client.query_points(
        collection_name=collection_name,
        query=query_vector,
        with_payload=True,
        limit=top_k
    ).points
    # print(search_result)
    return search_result

def insert(collection_name, vect_store_client, vectors, payloads=None):
    points = [
        PointStruct(id=idx, vector=vector, payload=payloads[idx])
        for idx, vector in enumerate(vectors)
    ]
    vect_store_client.upsert(
        collection_name=collection_name,
        points=points
    )

def generate_response(llm_client, question, question_date, context):
    prompt = LME_ANSWER_PROMPT.format(
        question=question,
        question_date=question_date,
        context=context
    )
    response = llm_client.chat.completions.create(
                model=MODEL_NAME,
                messages=[{"role": "system", "content": prompt}],
                # response_format={"type": "json_object"},
                temperature=0,
            )

    return response

with open("./data/longmemeval_s_cleaned.json", "r") as f:
    lines = json.load(f)[:2]


# for idx, line in enumerate(lines):
    # line = json.loads(line)
    # parsed_messages = parse_messages(line["conversation"])
def process_user_memory(line):
    dates = line.get("haystack_dates")
    sessions = line.get("haystack_sessions")
    question_date = line.get("question_date")
    question_date = question_date + " UTC"
    question_date_format = "%Y/%m/%d (%a) %H:%M UTC"
    question_date_string = datetime.strptime(question_date, question_date_format).replace(tzinfo=timezone.utc)
    question = line.get("question")
    golden_answer = line.get("golden_answer")

    for session_id, session in enumerate(sessions):
        date = dates[session_id] + " UTC"
        date_format = "%Y/%m/%d (%a) %H:%M UTC"
        date_string = datetime.strptime(date, date_format).replace(tzinfo=timezone.utc)
        
        parsed_messages = parse_messages(session) 
        print("parsed_messages:", parsed_messages)
        user_prompt = f"Input:\n{parsed_messages}"
        llm_response = openai_client.chat.completions.create(
            model=MODEL_NAME,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            response_format={"type": "json_object"},
        )
        response = llm_response.choices[0].message.content
        print(f"LLM è¿”å›žçš„åŽŸå§‹å“åº”: {response}")
        try:
            response = remove_code_blocks(response)
            if not response.strip():
                new_retrieved_facts = []
            else:
                try:
                    # First try direct JSON parsing
                    new_retrieved_facts = json.loads(response)["facts"]
                except json.JSONDecodeError:
                    # Try extracting JSON from response using built-in function
                    extracted_json = extract_json(response)
                    new_retrieved_facts = json.loads(extracted_json)["facts"]
        except Exception as e:
            print(f"Error in new_retrieved_facts: {e}")
            new_retrieved_facts = []
        print(f"æ–°æ£€ç´¢åˆ°çš„äº‹å®ž: {new_retrieved_facts}")

        retrieved_old_facts = []
        new_message_embeddings = {}
        try:
            for fact in new_retrieved_facts:
                embedding_vector = get_embedding(openai_client, fact, dimension=dimension)
                new_message_embeddings[fact] = embedding_vector
                # print(f"åŽŸå§‹æ–‡æœ¬: {fact}")
                # print(f"ç”Ÿæˆçš„åµŒå…¥ç»´åº¦: {len(embedding_vector)}")
                # print(f"åµŒå…¥å‘é‡çš„å‰ 5 ä¸ªæ•°å€¼: {embedding_vector[:5]}")
            
                # operation_info = vect_store_client.upsert(
                # collection_name=collection_name,
                # wait=True,
                # points=[
                #     PointStruct(id=str(uuid.uuid4()), 
                #                 vector=embedding_vector, 
                #                 payload={
                #                         "data": fact, 
                #                         "created_at": datetime.now(pytz.timezone('Asia/Shanghai')).isoformat()
                #                         }
                #                 )
                #                 ],
                # )
                # print(operation_info)

                existing_memories = search(collection_name, vect_store_client, embedding_vector, top_k=5)
                # print(f"æ£€ç´¢åˆ°çš„è®°å¿†ç‚¹: {existing_memories}")
                for mem in existing_memories:
                    retrieved_old_facts.append({"id": mem.id, "text": mem.payload.get("data", "")})
                    print("mem:", mem)
            # print(f"æ£€ç´¢åˆ°çš„æ—§äº‹å®ž: {retrieved_old_facts}")
        except Exception as e:
            print(f"ç”ŸæˆåµŒå…¥æ—¶å‡ºé”™ï¼Œè¯·æ£€æŸ¥æ‚¨çš„ API Key å’Œç½‘ç»œè¿žæŽ¥ï¼š{e}")


# # éªŒè¯ç‚¹æ˜¯å¦æˆåŠŸæ·»åŠ å’Œå­˜å‚¨
# points_data = vect_store_client.retrieve(
#     collection_name=collection_name,
#     ids=[pp], # æ‚¨æ’å…¥çš„ç‚¹çš„ID
#     with_payload=True, # ç¡®ä¿è¿”å›ž payload (åŸŽå¸‚ä¿¡æ¯)

# )

# print("\n--- æ£€ç´¢åˆ°çš„æ•°æ®ç‚¹ ---")
# for point in points_data:
#     print("point:", point)
#     print(f"ID: {point.id}, Payload: {point.payload}")
# print("-----------------------")

        unique_data = {}
        for item in retrieved_old_facts:
            unique_data[item["id"]] = item
        retrieved_old_facts = list(unique_data.values())

        temp_uuid_mapping = {}
        for idx, item in enumerate(retrieved_old_facts):
            temp_uuid_mapping[str(idx)] = item["id"]
            retrieved_old_facts[idx]["id"] = str(idx)
        print(f"ä¸´æ—¶ UUID æ˜ å°„: {temp_uuid_mapping}")
        print(f"ç”¨äºŽè®°å¿†æ›´æ–°çš„æ—§äº‹å®ž: {retrieved_old_facts}")
        if new_retrieved_facts:
            memory_action_prompt = get_update_memory_messages(retrieved_old_facts, new_retrieved_facts)
            # print("ç”¨äºŽæ›´æ–°è®°å¿†çš„æç¤º:", memory_action_prompt)
            response = openai_client.chat.completions.create(
                model=MODEL_NAME,
                messages=[{"role": "user", "content": memory_action_prompt}],
                response_format={"type": "json_object"},
            )
            update_response = response.choices[0].message.content

            try:
                if not update_response.strip() or not update_response:
                    new_memories_with_actions = {}
                else:
                    response = remove_code_blocks(update_response)
                    new_memories_with_actions = json.loads(response)
            except Exception as e:
                print(f"Invalid JSON response: {e}")
                new_memories_with_actions = {}

        else:
            new_memories_with_actions = {}

        returned_memories = []
        try:
            for resp in new_memories_with_actions.get("memory", []):
                try:
                    action_text = resp.get("text")
                    if not action_text:
                        print("Skipping memory entry because of empty `text` field.")
                        continue
                    embedding_vector = get_embedding(openai_client, action_text, dimension=dimension)
                    event_type = resp.get("event")
                    if event_type == "ADD":
                        memory_id = str(uuid.uuid4())
                        # memory_id = self._create_memory(
                        #     data=action_text,
                        #     existing_embeddings=new_message_embeddings,
                        #     metadata=deepcopy(metadata),
                        # )
                        operation_info = vect_store_client.upsert(
                        collection_name=collection_name,
                        wait=True,
                        points=[
                                PointStruct(
                                        id=memory_id, 
                                        vector=embedding_vector, 
                                        payload={
                                            "data": action_text, 
                                            # "created_at": datetime.now(pytz.timezone('Asia/Shanghai')).isoformat()
                                            "created_at": date_string.isoformat()
                                        })
                                ],
                        )
                        returned_memories.append({"id": memory_id, "memory": action_text, "event": event_type})
                    elif event_type == "UPDATE":
                        points_data = vect_store_client.retrieve(
                            collection_name=collection_name,
                            ids=[temp_uuid_mapping.get(resp.get("id"))],
                            with_payload=True, 
                        )
                        result = points_data[0] if points_data else None
                        if result:
                            old_memory = result.payload.get("data", "")
                        else:
                            old_memory = ""
                        created_at = result.payload.get("created_at", "") if result else ""
                        # new_updated_at = datetime.now(pytz.timezone('Asia/Shanghai')).isoformat()
                        new_updated_at = date_string.isoformat()
                        result.payload["data"] = action_text
                        result.payload["updated_at"] = new_updated_at
                        vect_store_client.upsert(
                            collection_name=collection_name,
                            points=[
                                PointStruct(
                                    id=temp_uuid_mapping.get(resp.get("id")), 
                                    vector=embedding_vector, 
                                    payload=result.payload
                                )
                            ],
                        )
                        returned_memories.append(
                            {
                                "id": temp_uuid_mapping.get(resp.get("id")),
                                "memory": action_text,
                                "event": event_type,
                                "previous_memory": old_memory,
                            }
                        )
                    elif event_type == "DELETE":
                        vect_store_client.delete(
                            collection_name=collection_name,
                            points_selector={
                                "points": [temp_uuid_mapping.get(resp.get("id"))],
                            }
                        )
                        returned_memories.append(
                            {
                                "id": resp.get("id"),
                                "memory": action_text,
                                "event": event_type,
                            }
                        )

                    elif event_type == "NONE":
                        # memory_id = temp_uuid_mapping.get(resp.get("id"))
                        returned_memories.append(
                            {
                                "id": temp_uuid_mapping.get(resp.get("id")),
                                "memory": action_text,
                                "event": event_type,
                            }
                        )
                except Exception as e:
                    print(f"Error processing memory action {resp}: {e}")       
        except Exception as e:
            print(f"Error iterating new_memories_with_actions: {e}")

        print(f"æœ€ç»ˆè¿”å›žçš„è®°å¿†æ“ä½œç»“æžœ: {returned_memories}")

def response_user(line):
    question = line.get("question")
    question_date = line.get("question_date")
    question_date = question_date + " UTC"
    question_date_format = "%Y/%m/%d (%a) %H:%M UTC"
    question_date_string = datetime.strptime(question_date, question_date_format).replace(tzinfo=timezone.utc)
    question = line.get("question")
    question_vector = get_embedding(openai_client, question, dimension=dimension)
    retrieved_memories = search(collection_name, vect_store_client, question_vector, top_k=topk)
    # context = "\n".join([mem.payload.get("data", "") for mem in retrieved_memories])
    memories_str = (
            "\n".join(
                f"- {mem.payload.get('created_at', '')}: {mem.payload.get('data', '')}"
                for mem in retrieved_memories
            )
        )
    response = generate_response(openai_client, question, question_date_string, memories_str)
    answer = response.choices[0].message.content

    return answer

# for idx, line in enumerate(lines):
#     print(f"\n\n==== å¤„ç†ç¬¬ {idx + 1} ä¸ªç”¨æˆ·çš„è®°å¿† ====")
#     process_user_memory(line)
#     print(f"\n\n==== ä¸ºç¬¬ {idx + 1} ä¸ªç”¨æˆ·ç”Ÿæˆå›žç­” ====")
#     answer = response_user(line)
#     print(f"ç”Ÿæˆçš„å›žç­”: {answer}")



# 1. ç»“æžœç´¯åŠ å™¨
evaluation_results = []
correct_count = 0
total_evaluated = 0

with open("./data/longmemeval_s_cleaned.json", "r") as f:
    lines = json.load(f)[:2] # ä»åªå¤„ç†å‰ 2 ä¸ªç”¨æˆ·

for idx, line in enumerate(lines):
    print(f"\n\n==== å¤„ç†ç¬¬ {idx + 1} ä¸ªç”¨æˆ·çš„è®°å¿† (å­˜å‚¨é˜¶æ®µ) ====")
    process_user_memory(line)
    
    print(f"\n\n==== ä¸ºç¬¬ {idx + 1} ä¸ªç”¨æˆ·ç”Ÿæˆå›žç­” (æ£€ç´¢é˜¶æ®µ) ====")
    answer = response_user(line)
    golden_answer = line.get("golden_answer") # èŽ·å–é»„é‡‘ç­”æ¡ˆ
    question = line.get("question") # èŽ·å–é—®é¢˜

    print(f"ç”Ÿæˆçš„å›žç­”: {answer}")
    print(f"é»„é‡‘ç­”æ¡ˆ: {golden_answer}")
    
    # 2. è°ƒç”¨ Grader è¿›è¡Œè¯„ä¼°
    is_correct = lme_grader(openai_client, question, golden_answer, answer)
    
    # 3. ç»Ÿè®¡ç»“æžœ
    total_evaluated += 1
    if is_correct:
        correct_count += 1
        evaluation_results.append(True)
    else:
        evaluation_results.append(False)

    print(f"LLM è¯„ä¼°ç»“æžœ: {'CORRECT' if is_correct else 'WRONG'}")
    print(f"å½“å‰ç´¯è®¡å‡†ç¡®çŽ‡: {correct_count / total_evaluated:.4f} ({correct_count}/{total_evaluated})")


# 4. è®¡ç®—æœ€ç»ˆæ€»å‡†ç¡®çŽ‡
print("\n\n==================================================")
print("             ðŸŽ¯ æœ€ç»ˆè¯„ä¼°ç»“æžœ")
print("==================================================")

if total_evaluated > 0:
    final_accuracy = correct_count / total_evaluated
    print(f"æ€»è¯„ä¼°é—®é¢˜æ•°: {total_evaluated}")
    print(f"æ­£ç¡®å›žç­”æ•°: {correct_count}")
    print(f"æœ€ç»ˆæ€»å‡†ç¡®çŽ‡: {final_accuracy:.4f} ({final_accuracy * 100:.2f}%)")
else:
    print("æ²¡æœ‰è¯„ä¼°ä»»ä½•é—®é¢˜ã€‚")
print("==================================================")